# 特征工程

## 1 机器学习

机器学习简单来说就是选择一种学习算法，从数据中学习并建立成模型来对新的数据进行预测的计算机科学 。

机器学习是人工智能的一个分支。人工智能的研究是从以“推理”为重点—以“知识”为重点—再到以“学习”为重点，一条自然、清晰的脉络。机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习算法是一类从数据中自动分析获得规律(模型)，并利用规律对未知数据进行预测的算法。

我们的数据量越来越多，硬件越来越强悍。急需要解放人的生产力，自动去寻找数据的规律。解决更多专业领域的问题。机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。

机器学习适用于以下等问题：

- 不存在已知算法解决方案的复杂问题 
-  需要大量手动调整或者规则列表超长的问题 
- 可以适应环境波动的系统 

### 1.1 基础概念

机器学习分为四种，分别是监督学习、无监督学习、半监督学习和增强学习。使用比较多的的是监督学习与无监督学习。

- #### 监督学习

利用无标签的数据学习数据的分布或数据与数 据之间的关系被称作无监督学习，也就是说，通过过往的一些数据的特征以及最终结果来进行训练的方式就是监督学习法，监督学习算法的训练数据源需要由特征值以及目标队列两部分组成。

监督学习依赖于每个样本，可以得到每个特征序列映射到的确切的目标值是什么，所以常用于回归以及分类场景。常见的监督学习算法有：K近邻、朴素贝叶斯、决策树、随机森林、GBDT、支持向量机逻辑回归、线性回归等。

- #### 无监督学习

练样本不依赖于打标数据的机器学习算法，它主要是用来解决一些聚类场景的问题。相较于监督学习，无监督学习的一大好处就是不依赖于打标数据。常见的无监督学习算法有:K-Means、DBSCAN、协同过滤等。

- #### 半监督学习

通过对样本的部分打标来进行机器学习算法的使用，很多半监督学习算法都是监督学习算法的变形。半监督学习解决的是一些打标数据比较难获得的分类场景，比如：标签传播、

- #### 增强学习

是一种比较复杂的机器学习种类， 强调的是系统与外界不断地交互，获得外界的反馈，然后决定自身的行为。强化学习主要是针对流程中不断需要推理的场景，比如:隐马尔可夫。

**以上就是我们机器学习的大体分类。在我们学习过程中，还会遇到一些常见的名词。**

- #### 样本与标签

**标签**是提供给算法的包含所需解决方案的训练数据，是我们要预测的事物，即简单线性回归中的 y 变量。

**样本**每一条数据叫一个样本，即数据的特定实例：`x` 。

- #### 特征

属性加上其值 就是特征，也可以理解为输入变量，即简单线性回归中的 `x` 变量。

- #### 回归任务

关注预测值和真实值之间的差别，就是通过给定的特征来预测一个目标数值。

- #### 训练集

 用于训练模型的数据叫训练集 

- #### 测试集

用于测试模型精度的数据叫测试集

- #### 过拟合与欠拟合

从字面的意义上理解就是过度拟合的意思，常发生在线性分类器或者线性模型的训练和预测当中。过拟合的原理就是机器学习算法过度学习了训练集数据。反之欠拟合。

- #### 模型训练

是指创建或学习模型。也就是说，向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。通过训练数据找到算法最合适的参数。

### 1.2 机器学习执行流程

![1574144721121](image/1574144721121.png)

1. ##### 理解实际问题，抽象为机器学习能处理的数学问题

   理解实际业务场景问题是机器学习的第一步， 机器学习中特征工程和模型训练都是非常费时的，深入理解要处理的问题，能避免走很多弯路。理解问题，明确可以获得的数据。

2. ##### 获取数据

   获取数据包括获取原始数据，以及从原始数据中经过特征工程，从原始数据中提取训练、测试数据。数据数量不要有多个数量级的差距。不仅如此还要对评估数据的量级，样本数量、特征数量，估算训练模型对内存的消耗。

3. ##### 特征工程

   特征工程包括从原始数据中特征构建、特征提取、特征选择。特征工程做的好能发挥原始数据的最大效力，往往能够使得算法的效果和性能得到显著的提升，有时能使简单的模型的效果比复杂的模型效果好。

4. ##### 模型训练、诊断、调优

   对算法的理解、调节参数，使模型达到最优。模型诊断中至关重要的是判断过拟合、欠拟合，常见的方法是绘制学习曲线，交叉验证。通过增加训练的数据量、降低模型复杂度来降低过拟合的风险,提高特征的数量和质量、增加模型复杂来防止欠拟合。诊断后的模型需要进行进一步调优， 调优后的新模型需要重新诊断，这是一个反复迭代不断逼近的过程，需要不断的尝试，进而达到最优的状态。

5. ##### 模型预测，获得结果

   我们通过训练数据集得到模型，然后将想要预测的数据加入模型中进行测试，得到测试结果。

这就是我们大致的机器学习流程。

### 1.3 数据处理与特征工程

- ##### 数据处理

“数据决定了机器学习的上限，而算法只是尽可能逼近这个上限”，这句话很好的阐述了数据在机器学习中的重要性。大部分直接拿过来的数据都是特征不明显的、没有经过处理的或者说是存在很多无用的数据，那么需要进行一些特征处理，特征的缩放等等，满足训练数据的要求。

数据处理主要解决的问题是：

1. 数据量不足

2. 训练数据不具备代表性

3. 质量差的数据

4. 特征筛选

- ##### 特征工程

机器学习的关键是 提取出一组好的用来训练的特征集，这个过 程叫特征工程，包括： 

1. 特征选择 从现有特征中选择最有用的特征进行训练 

2. 特征提取 将现有特征进行整合，产生更有用的特征，比 如降维算法 

3. 通过收集 新数据创造新特征

#### 1.3.1 数据的来源与类型

- ##### 数据的来源

通过爬虫爬取、购买数据、网上的开放数据等。

- ##### 数据的类型

按照机器学习的数据分类我们可以将数据分成：

- 标称型：标称型目标变量的结果只在有限目标集中取值，如真与假
- 数值型：数值型目标变量则可以从无限的数值集合中取值，

按照数据的本身分布特性

- 离散型【无规律】
- 连续型【有规律】
  - 离散变量是指其数值只能用自然数或整数单位计算的则为离散变量。例如，班级人数
  - 连续型数据是指在指定区间内可以是任意一个数值。例如，票房数据、

#### 1.3.2 数据特征选择

特征选择主要有两个功能：

- 减少特征数量，降维，使模型泛化能力更强，减少过拟合
- 增强特征和特征值之间的理解

降维本质上是从一个维度空间映射到另一个维度空间，特征的多少类别没有减少，当然在映射的过程中特征值也会相应的变化。举个例子，现在的特征是1000维，我们想要把它降到500维。降维的过程就是找个一个从1000维映射到500维的映射关系。

#### 1.3.3 数据的特征抽取

现实世界中多数特征都不是连续变量，比如分类、文字、图像等，为了对非连续变量做特征表述，需要对这些特征做数学化表述，因此就用到了特征提取

#### 1.3.4 数据特征处理

- ##### 单个特征

  - 归一化【归一化首先在特征（维度）非常多的时候，可以防止某一维或某几维对数据影响过大，也是为了把不同来源的数据统一到一个参考区间下，这样比较起来才有意义，其次可以程序可以运行更快。】
  - 标准化【将数据转化为同一量级，避免量级对结果产生不利的影响①离差标准化②标准差标准化③小数定标标准化】

  - 缺失值【①删除 ----会对数据产生很大的影响，造成数据缺失，所以在数据大部分为缺失值，才使用删除法；②填充  --- 填充之后对结果影响不大的情况，可以使用(均值，中位数，众数)；③插值(线性插值；多项式插值；样条插值)】

- ##### 多个特征

  - 降维【保存数据集中对方差影响最大的那些特征，或者进行抽样】

## 2 机器学习流程实践

### 2.1 获取数据

#### 2.1.1 模块安装

```
pip install jupyter numpy pandas scipy matplotlib  scikit-learn
```

- 测试安装模块

```
python -c 'import jupyter, numpy, pandas, scipy, matplotlib, scikit-learn'
```









































